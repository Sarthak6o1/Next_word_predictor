# -*- coding: utf-8 -*-
"""LSTM_next_word_predictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gfO7UzLApHXy5RL3dXwCHkZO8OmMWG_3
"""

import kagglehub
dorianlazar_medium_articles_dataset_path = kagglehub.dataset_download('dorianlazar/medium-articles-dataset')

print('Data source import complete.')

import pandas as pd
import os
import numpy as np

import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
import kagglehub

csv_file_path = os.path.join(dorianlazar_medium_articles_dataset_path, 'medium_data.csv')
medium_data = pd.read_csv(csv_file_path)
medium_data.head(15)

print("Records Total: ", medium_data.shape[0])
print("Fields Total: ", medium_data.shape[1])

medium_data['title']

medium_data['title'] = medium_data['title'].apply(lambda x: x.replace(u'\xa0',u' '))
medium_data['title'] = medium_data['title'].apply(lambda x: x.replace('\u200a',' '))

tokenizer = Tokenizer(oov_token='<oov>')
tokenizer.fit_on_texts(medium_data['title'])
total_words = len(tokenizer.word_index) + 1

print("Total number of words: ", total_words)
print("<oov>: ", tokenizer.word_index['<oov>'])
print("Strong: ", tokenizer.word_index['strong'])
print("And: ", tokenizer.word_index['and'])
print("Consumption: ", tokenizer.word_index['consumption'])

input_sequences = []
for line in medium_data['title']:
    token_list = tokenizer.texts_to_sequences([line])[0]

    for i in range(1, len(token_list)):
        n_gram_sequence = token_list[:i+1]
        input_sequences.append(n_gram_sequence)

print("Total input sequences: ", len(input_sequences))

max_sequence_len = max([len(x) for x in input_sequences])
input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))
print(input_sequences)

x = input_sequences[:,:-1]
labels=input_sequences[:,-1]
y = tf.keras.utils.to_categorical(labels, num_classes=total_words)

model = Sequential()
model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))
model.add((LSTM(150)))
model.add(Dense(total_words, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(x, y, epochs=50, verbose=1)
print(model)

print(model.summary())

import matplotlib.pyplot as plt
def plot_graphs(history, string):
    plt.plot(history.history[string])
    plt.xlabel("Epochs")
    plt.ylabel(string)
    plt.show()

plot_graphs(history, 'accuracy')

plot_graphs(history, 'loss')

import time
text = input("Enter a text: ")

for i in range(10):
  token_text = tokenizer.texts_to_sequences([text])[0]
  padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')
  pos = np.argmax(model.predict(padded_token_text))

  for word,index in tokenizer.word_index.items():
    if index == pos:
      text = text + " " + word
      print(text)
      time.sleep(2)

import numpy as np
from IPython.display import Audio
from google.colab import output

def speak(text):
  output.eval_js(f'new Audio("https://dict.youdao.com/dictvoice?audio={text}").play()')

text = input("Enter a text: ")

for i in range(9):
  token_text = tokenizer.texts_to_sequences([text])[0]
  padded_token_text = pad_sequences([token_text], maxlen=max_sequence_len-1, padding='pre')
  predicted_probabilities = model.predict(padded_token_text, verbose=0)[0]
  pos = np.argmax(predicted_probabilities)

  for word,index in tokenizer.word_index.items():
    if index == pos:
      text = text + " " + word
      print(text)
      speak(word)
      time.sleep(2)